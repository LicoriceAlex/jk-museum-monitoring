name: jk-museum # имя проекта compose

services:
  prometheus:
    image: prom/prometheus:v3.5.0 # образ prometheus
    container_name: prometheus
    command:
      - --config.file=/etc/prometheus/prometheus.yml
      - --storage.tsdb.path=/prometheus
      - --storage.tsdb.retention.time=15d # ретеншн 15 дней
      - --web.enable-lifecycle # позволяет перезагружать конфиг по http
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./monitoring/prometheus/alerts.yml:/etc/prometheus/alerts.yml:ro
      - prometheus_data:/prometheus
    ports: ["9090:9090"] # ui prometheus
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 512m

  amcfg:
    image: alpine:3.20 # легкий образ для генерации конфига
    container_name: amcfg
    env_file: .env # подцепляем переменные окружения
    working_dir: /work
    volumes:
      - ./monitoring/alertmanager:/work
    entrypoint: ["/bin/sh","-c"]
    command: >
      "apk add --no-cache gettext >/dev/null &&
       envsubst < /work/alertmanager.tmpl.yml > /work/alertmanager.yml"
    # генерим alertmanager.yml из шаблона с env переменными

  alertmanager:
    image: prom/alertmanager:v0.27.0 # образ alertmanager
    container_name: alertmanager
    command: ["--config.file=/etc/alertmanager/alertmanager.yml"]
    volumes:
      - ./monitoring/alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
    ports: ["9093:9093"] # ui alertmanager
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 256m
    depends_on:
      amcfg:
        condition: service_completed_successfully # ждём генерации конфига

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.52.1 # образ cadvisor
    container_name: cadvisor
    privileged: true # нужен доступ к системным метрикам
    ports: ["8080:8080"] # ui cadvisor по желанию
    volumes:
      - /:/rootfs:ro # корневая fs только чтение
      - /var/run:/var/run:ro # доступ к docker сокету
      - /sys:/sys:ro # системные метрики
      - /var/lib/docker/:/var/lib/docker:ro # метаданные docker
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 512m

  node-exporter:
    image: prom/node-exporter:v1.9.0 # метрики хоста
    container_name: node-exporter
    pid: host # видеть процессы хоста
    network_mode: host # слушать 9100 на хосте
    command: ["--path.rootfs=/host"] # корень хоста смонтирован как /host
    volumes:
      - /:/host:ro
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "0.3"
          memory: 256m

  grafana:
    image: grafana/grafana:12.1.2 # grafana
    container_name: grafana
    environment:
      - GF_SECURITY_ADMIN_USER=admin # логин админа
      - GF_SECURITY_ADMIN_PASSWORD=admin # пароль админа
      - GF_USERS_DEFAULT_THEME=dark # светлая тема по умолчанию
    volumes:
      - grafana_data:/var/lib/grafana # данные grafana
      - ./monitoring/grafana/provisioning/datasources:/etc/grafana/provisioning/datasources # источники
      - ./monitoring/grafana/provisioning/dashboards:/etc/grafana/provisioning/dashboards # дашборды
    ports: ["3001:3000"] # ui grafana на 3001
    depends_on: [prometheus]
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 1g

  loki:
    image: grafana/loki:3.5.6 # loki для логов
    container_name: loki
    command: ["-config.file=/etc/loki/local-config.yaml"]
    volumes:
      - ./monitoring/loki/local-config.yaml:/etc/loki/local-config.yaml:ro
      - loki_data:/loki
    ports: ["3100:3100"] # api loki
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 512m

  promtail:
    image: grafana/promtail:3.5.6 # агент логов
    container_name: promtail
    command: ["-config.file=/etc/promtail/config.yml"]
    volumes:
      - /var/lib/docker/containers:/var/lib/docker/containers:ro # json логи контейнеров
      - /var/run/docker.sock:/var/run/docker.sock:ro # docker api
      - ./monitoring/promtail/config.yml:/etc/promtail/config.yml:ro
      - promtail_positions:/positions # позиции логов
    depends_on: [loki]
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 512m
        reservations:
          memory: 256m

volumes:
  prometheus_data: # данные prometheus
  grafana_data: # данные grafana
  loki_data: # данные loki
  promtail_positions: # позиции promtail

networks:
  default:
    external: true
    name: jk-museum-dev_default # используем уже существующую сеть проекта
